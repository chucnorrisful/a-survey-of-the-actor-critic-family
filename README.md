# A survey of the actor-critic family
*University Seminar Paper, not reviewed.*

Survey/overview over the evolution of actor-critic reinforcement learning algorithms over time, including state-of-the-art of 2021 (time of writing the paper&poster).

![Timeline diagram of reinforcement learning algorithms over time, from 201633-2021](https://github.com/chucnorrisful/a-survey-of-the-actor-critic-family/blob/main/history_of_AC.png?raw=true)

## Abstract:

Actor-critic algorithms are at the forefront of the fast evolving research field of reinforcement learning. 
Recent breakthroughs, like [beating the world-champion in the game of Go](https://www.nature.com/articles/nature16961) in 2015,
as well as [reaching Grandmaster level in StarCraftII](https://www.nature.com/articles/s41586-019-1724-z), used
variants of the actor-critic framework. This catalysed the development of many variants and improvements, cross-influenced by the
progress made on different model-free reinforcement learning algorithms. This work gives an overview over the state of the art
of actor-critic algorithms, with a focus on popular benchmarks
like the [Arcade Learning Environment](https://www.jair.org/index.php/jair/article/view/10819) and [MuJoCo](https://ieeexplore.ieee.org/abstract/document/6386109). 

First, an introduction to the actor-critic framework is given. Two
popular benchmarks are described, followed by the history of different improvements and algorithms over the past 6 years. Finally,
current state-of-the-art actor-critic methods are presented. The work
concludes with a discussion about the difficulty of comparing different reinforcement learning algorithms.

### Read further:

This repository is linked a QR-Code on the poster, to provide the full seminar-paper to curious readers, as well as the included full list of references.
The PDF version of the poster can be found here aswell.

Links:
- [seminar-paper](A_Survey_of_the_Actor_Critic_Family.pdf)
- [poster](A_Survey_of_the_Actor_Critic_Family_Poster.pdf)
